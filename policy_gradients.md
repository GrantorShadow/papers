# Policy Gradients

"Always try to learn a policy directly" - Take with a grain of salt

Model Based RL
'Easy to learn model'
Learns all there is to know from data
Objectives capture irrelevant info
Computation is non trivial

Value Based RL
Closer to true objective
Fairly well understood
Still not true objjective
Vauke function might be complex but policy won't.

Policy Based RL
Right objective
Ignores other learnable knowledge

Approximating policy results in model free reinforcement learning